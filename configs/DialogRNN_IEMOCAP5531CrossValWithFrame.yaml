exp_mode: train
show_tsne: false
checkpoints:
  filename: '{epoch}-{val_loss:.5f}-{val_accuracy:.5f}'
  monitor: val_accuracy
  save_last: true
  save_on_train_epoch_end: false
  save_top_k: 10
  mode: max
data_loader:
  batch_size: 2
  num_workers: 0
dataset:
  name: IEMOCAP5531CrossValWithFrame
  data_path: data/featuresFromPretrain/wavlm_large_finetune_fold1_with_val_s3prl_full_mean_hidden.pkl
  cross_val: 1
  max_sentences: 120
  noValid: false
earlystop:
  monitor: val_accuracy
  check_on_train_epoch_end: false
  patience: 20
  mode: max
lr_scheduler:
  active: false
  decay_rate: 0.9
model:
  adapter:
    projector_dim: 512
    select: DeepModel
    UtteranceLevel:
      pooling: MeanPooling
    DeepModel:
      model_type: CNNSelfAttention
      hidden_dim: 256
      kernel_size: 5
      padding: 2
      pooling: 5
      dropout: 0.4
    output_dim: 256
  dialogModel:
    base_model: LSTM
    D_m: null    # input_size
    D_g: 150    # only dialogRnn
    D_p: 150    # only dialogRnn
    D_e: 256    # hidden_size
    D_h: 128   # unused
    D_a: 128   # unused
    graph_hidden_size: 100 
    n_speakers: 2
    max_seq_len: 110 
    window_past: 10
    window_future: 10
    dropout_rec: 0.5 # only dialogRnn
    dropout: 0.5
    nodal_attention: True
    avec: False
  uttr_input_dim: 1024
  classes_name:
  - 'N'
  - A
  - S
  - H
optimizer:
  learning_rate: 0.0001
  type: Adam
  weight_decay: 1.0e-05
seed: 100
trainer:
  log_every_n_steps: 1
  max_epochs: 500
  accelerator: gpu
  devices:
  - 0