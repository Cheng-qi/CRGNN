checkpoints:
  filename: '{epoch}-{val_loss:.5f}-{val_accuracy:.5f}'
  monitor: val_accuracy
  save_last: true
  save_top_k: 10
data_loader:
  batch_size: 50
  num_workers: 10
dataset:
  # data_path: /home/projects/12001458/chengqi/conv-emotion/AudioDialogueGCN/IEMOCAP_features/features/f/cross_val5/features/epoch=155-val_loss=3.81424-val_accuracy=0.71152_audio_linear.pkl
  data_path: /home/users/ntu/n2107167/lnespnet/chengqi/ADGCNForEMC/datasets/iemocap_original/audio/IEMOCAP_Audio_4.csv
  cross_val: 5
earlystop:
  monitor: val_loss
  patience: 300
lr_scheduler:
  active: false
  decay_rate: 1
model:
  n_classes: 4
  adaptive_size: 2
  classModel: ADGCN
  linkerModel_cnn1: [5, 2]
  linkerModel_cnn2: [3, 1]
  pretrain_model: "d2v"
  graph_input_size: 512
  gat_head: 5
  graph_hidden_size: 128
  dropout: 0.5
  gnn_layers: 10
  alpha: 0.2
  theta: 0.5
optimizer:
  learning_rate: 0.001
  type: Adam
  weight_decay: 0.00001
seed: 100
trainer:
  gpus: [0]
  # - 2
  log_every_n_steps: 1
  max_epochs: 500
  # resume_from_checkpoint: /home/projects/12001458/chengqi/mutilModal/lightning_logs/version_78/checkpoints/last.ckpt

